<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Lecture Assistant (Gemini)</title>
  <style>
    body { font-family: Arial, sans-serif; margin: 2em; background: #f4f4f9; }
    h1 { color: #333; }
    button { margin: 0.5em 0; padding: 0.6em 1em; border: none; border-radius: 5px; cursor: pointer; background: #4CAF50; color: white; }
    button:hover { background: #45a049; }
    input[type="file"], input[type="text"] { margin: 0.5em 0; padding: 0.5em; width: 100%; max-width: 400px; }
    textarea { width: 100%; height: 150px; margin: 1em 0; padding: 0.7em; }
    .output { background: #fff; padding: 1em; border-radius: 5px; margin-top: 1em; box-shadow: 0 0 5px rgba(0,0,0,0.1); }
  </style>
</head>
<body>
  <h1>üéôÔ∏è Lecture Assistant (Gemini)</h1>

  <h3>üîë API Key</h3>
  <input type="text" id="apiKeyInput" placeholder="Enter Gemini API Key">
  <button onclick="saveApiKey()">Save API Key</button>

  <h3>üé§ Record Lecture</h3>
  <button onclick="startRecording()">Start Recording</button>
  <button onclick="stopRecording()">Stop Recording</button>

  <h3>üìÇ Or Upload MP3</h3>
  <input type="file" id="fileInput" accept="audio/mp3" onchange="uploadMP3(event)">

  <h3>üìÑ Transcript</h3>
  <textarea id="transcript" placeholder="Transcript will appear here..."></textarea>
  <button onclick="summarize()">Summarize</button>

  <h3>‚ùì Ask a Question</h3>
  <input type="text" id="questionInput" placeholder="Ask a question about the lecture">
  <button onclick="askQuestion()">Ask</button>

  <div class="output">
    <h3>üìù Output</h3>
    <div id="outputText"></div>
  </div>

  <script>
    let mediaRecorder, audioChunks = [];
    const apiUrl = "https://generativelanguage.googleapis.com/v1beta/models";

    // Load API key from localStorage
    document.getElementById("apiKeyInput").value = localStorage.getItem("gemini_api_key") || "";

    function saveApiKey() {
      const key = document.getElementById("apiKeyInput").value.trim();
      if (key) {
        localStorage.setItem("gemini_api_key", key);
        alert("API Key saved!");
      }
    }

    function getApiKey() {
      return localStorage.getItem("gemini_api_key");
    }

    async function startRecording() {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      mediaRecorder = new MediaRecorder(stream);
      audioChunks = [];
      mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
      mediaRecorder.start();
    }

    function stopRecording() {
      mediaRecorder.stop();
      mediaRecorder.onstop = async () => {
        const blob = new Blob(audioChunks, { type: 'audio/webm' });
        await transcribe(blob);
      };
    }

    async function uploadMP3(event) {
      const file = event.target.files[0];
      if (file) {
        await transcribe(file);
      }
    }

    async function transcribe(fileOrBlob) {
      const apiKey = getApiKey();
      if (!apiKey) return alert("Please enter and save your Gemini API key first!");

      const formData = new FormData();
      formData.append("file", fileOrBlob);

      // Gemini does not have direct Whisper-like transcription yet ‚Üí you‚Äôd route through another service (e.g. OpenAI Whisper API or AssemblyAI)
      // Here we stub: Convert audio ‚Üí base64 and send to Gemini multimodal endpoint (experimental)
      const arrayBuffer = await fileOrBlob.arrayBuffer();
      const base64Audio = btoa(String.fromCharCode(...new Uint8Array(arrayBuffer)));

      const resp = await fetch(`${apiUrl}/gemini-1.5-flash:generateContent?key=${apiKey}`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          contents: [{
            parts: [
              { text: "Transcribe the following lecture audio into text." },
              { inline_data: { mime_type: "audio/mp3", data: base64Audio } }
            ]
          }]
        })
      });

      const data = await resp.json();
      document.getElementById("transcript").value = data.candidates?.[0]?.content?.parts?.[0]?.text || "Transcription failed.";
    }

    async function summarize() {
      const apiKey = getApiKey();
      if (!apiKey) return alert("Please enter and save your Gemini API key first!");

      const transcript = document.getElementById("transcript").value;
      if (!transcript) return alert("No transcript to summarize!");

      const resp = await fetch(`${apiUrl}/gemini-1.5-flash:generateContent?key=${apiKey}`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          contents: [{ parts: [{ text: "Summarize this lecture:\n\n" + transcript }] }]
        })
      });

      const data = await resp.json();
      document.getElementById("outputText").innerText = data.candidates?.[0]?.content?.parts?.[0]?.text || "Summarization failed.";
    }

    async function askQuestion() {
      const apiKey = getApiKey();
      if (!apiKey) return alert("Please enter and save your Gemini API key first!");

      const transcript = document.getElementById("transcript").value;
      const question = document.getElementById("questionInput").value;
      if (!transcript || !question) return alert("Need both transcript and question!");

      const resp = await fetch(`${apiUrl}/gemini-1.5-flash:generateContent?key=${apiKey}`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          contents: [{ parts: [{ text: `Lecture transcript:\n${transcript}\n\nQuestion: ${question}` }] }]
        })
      });

      const data = await resp.json();
      document.getElementById("outputText").innerText = data.candidates?.[0]?.content?.parts?.[0]?.text || "Answer failed.";
    }
  </script>
</body>
</html>